{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fraud detection\n",
    "\n",
    "Creation of models to predict instances of fraud using data based on [this dataset from Kaggle](https://www.kaggle.com/dalpozz/creditcardfraud).\n",
    " \n",
    "Each row in `fraud_data.csv` corresponds to a credit card transaction. Features include confidential variables `V1` through `V28` as well as `Amount` which is the amount of the transaction. \n",
    " \n",
    "The target is stored in the `class` column, where a value of 1 corresponds to an instance of fraud and 0 corresponds to an instance of not fraud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 21337, 1: 356})\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "df = pd.read_csv(\"fraud_data.csv\")\n",
    "\n",
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]\n",
    "\n",
    "# Distribution of each class data\n",
    "counter = Counter(y)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 4266, 1: 2133})\n"
     ]
    }
   ],
   "source": [
    "# The dataset is unbalanced, we need to oversample the fraud class data and undersample the other class data\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# First we oversample the fraud class using the SMOTE method to reach 10% of the non-fraud class data length\n",
    "over = SMOTE(sampling_strategy=0.1)\n",
    "# Then we undersample the non-fraud class data to twice the number of the fraud class data\n",
    "under = RandomUnderSampler(sampling_strategy=0.5)\n",
    "# We can build a pipeline to chain the transformations\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "X, y = pipeline.fit_resample(X, y)\n",
    "\n",
    "# New distribution\n",
    "counter = Counter(y)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can build several models and evaluate them\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "clf_svc = SVC().fit(X_train, y_train)\n",
    "clf_rfdt = RandomForestClassifier().fit(X_train, y_train)\n",
    "\n",
    "# Logistic regression need a scaling transformation\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "clf_lr = LogisticRegression().fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall svc : 0.7693439324471418\n",
      "Recall rfdt : 0.9578025530230564\n",
      "Recall lr : 0.8706083495508571\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from numpy import mean\n",
    "\n",
    "# Test recall for the three models\n",
    "print(\"Recall svc :\", mean(cross_val_score(clf_svc, X, y, scoring='recall')))\n",
    "print(\"Recall rfdt :\", mean(cross_val_score(clf_rfdt, X, y, scoring='recall')))\n",
    "print(\"Recall lr :\", mean(cross_val_score(clf_lr, scaler.fit_transform(X), y, scoring='recall')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best param : {'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "# The best model is the random forest decision tree, we can now optimise its parameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_values = {\"n_estimators\":[10, 50, 100, 200]}\n",
    "grid_rfdt = GridSearchCV(clf_rfdt, param_grid = grid_values, scoring = 'recall').fit(X_train, y_train)\n",
    "print(\"Best param :\",grid_rfdt.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall rfdt : 0.9620224076700641\n"
     ]
    }
   ],
   "source": [
    "# Optimisation of the model and final evaluation\n",
    "clf_rfdt = RandomForestClassifier(n_estimators=200, random_state=0).fit(X_train, y_train)\n",
    "print(\"Recall rfdt :\", mean(cross_val_score(clf_rfdt, X, y, scoring='recall')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "import pickle\n",
    "\n",
    "with open('./fraud_detection.pkl','wb') as model:\n",
    "    pickle.dump(clf_rfdt, model)"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-machine-learning",
   "graded_item_id": "5yX9Z",
   "launcher_item_id": "eqnV3",
   "part_id": "Msnj0"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
